{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from cvxopt import matrix, solvers\n",
    "solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_class = ['Euro Bonds','US Bonds', 'Canada', 'France', 'Germany', 'Japan', 'UK', 'US']\n",
    "mean = np.array([0.27, 0.25, 0.39, 0.88, 0.53, 0.88, 0.79, 0.71])\n",
    "sd_percent = [1.56, 2.01, 5.50, 7.03, 6.22, 7.04, 6.01, 4.30]\n",
    "sd = np.array([0.01*x for x in sd_percent])\n",
    "corr = np.array([[1.00, 0.92, 0.33, 0.26, 0.28, 0.16, 0.29, 0.42], \n",
    "                 [0.92, 1.00, 0.26, 0.22, 0.27, 0.14, 0.25, 0.36], \n",
    "                 [0.33, 0.26, 1.00, 0.41, 0.30, 0.25, 0.58, 0.71],\n",
    "                 [0.26, 0.22, 0.41, 1.00, 0.62, 0.42, 0.54, 0.44],\n",
    "                 [0.28, 0.27, 0.30, 0.62, 1.00, 0.35, 0.48, 0.34],\n",
    "                 [0.16, 0.14, 0.25, 0.42, 0.35, 1.00, 0.40, 0.22],\n",
    "                 [0.29, 0.25, 0.58, 0.54, 0.48, 0.40, 1.00, 0.56],\n",
    "                 [0.42, 0.36, 0.71, 0.44, 0.34, 0.22, 0.56, 1.00]])\n",
    "sd_down = np.tile(sd,(8,1))\n",
    "sd.shape = (8,1)\n",
    "sd_right = np.tile(sd,(1,8))\n",
    "cov = sd_down*corr*sd_right\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Variance Efficient Frontier Algorithm & Resampling Efficient Frontier Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 51 portfolios equally spaced with respect to return\n",
    "# mu, sigma should be np.ndarray\n",
    "def MVEF(mu, sigma, k=51):\n",
    "    \n",
    "    n = len(mu)\n",
    "    c = matrix(mu)   \n",
    "    h = matrix(-np.zeros(n))\n",
    "    G = matrix(-np.identity(n))\n",
    "    b = matrix(1.0)\n",
    "    A = matrix(np.ones(n)).T\n",
    "\n",
    "    # find r_min, r_max:\n",
    "    r_min_solver = solvers.lp(c,G,h,A,b)\n",
    "    r_min_weight = np.array(r_min_solver['x'])\n",
    "    r_min = r_min_weight.T.dot(mu)\n",
    "    \n",
    "    r_max_solver = solvers.lp(-c,G,h,A,b)\n",
    "    r_max_weight = np.array(r_max_solver['x'])\n",
    "    r_max = r_max_weight.T.dot(mu)\n",
    "    \n",
    "    assert(r_min < r_max)\n",
    "    \n",
    "    r_rank = np.linspace(r_min,r_max,k)\n",
    "    \n",
    "    # build efficient frontier:\n",
    "    ef_sd = []\n",
    "    opt_weight = []\n",
    "    G_hat = -matrix(np.vstack((mu.T,\n",
    "                              np.identity(n))))\n",
    "    for r in r_rank:\n",
    "        P = 2*matrix(sigma)\n",
    "        q = matrix(np.zeros(n))\n",
    "        zero = np.zeros(n)\n",
    "        zero.shape = (n,1)\n",
    "        h_hat = -matrix(np.vstack((np.array([r]),zero)))\n",
    "        ef_solver = solvers.qp(P,q,G_hat,h_hat,A,b)\n",
    "        #ef_solver.options['show_progress'] = False\n",
    "        weight = np.array(ef_solver['x'])\n",
    "        opt_weight.append(weight)        \n",
    "        ef_sigma = np.sqrt(weight.T.dot(sigma.dot(weight))[0,0])\n",
    "        ef_sd.append(ef_sigma)\n",
    "        \n",
    "    return ef_sd, r_rank, opt_weight\n",
    "\n",
    "def REF(mu, sigma, months=18*12, k=51, m=500):\n",
    "    size = len(mu)\n",
    "    REF_weights = [np.zeros((size,1)) for i in range(k)]\n",
    "    REF_mean = []\n",
    "    REF_sd = []\n",
    "    for i in range(m):\n",
    "        sample = np.random.multivariate_normal(mu, sigma, size).T\n",
    "        sample_cov = np.cov(sample)\n",
    "        sample_mean = np.mean(sample, 1)\n",
    "        ref_sd, ref_r, ref_opt_weights = MVEF(sample_mean, sample_cov, k)\n",
    "        for weight_REF, weight_ref in zip(REF_weights, ref_opt_weights):\n",
    "            weight_REF += weight_ref\n",
    "    for weight_REF in REF_weights:\n",
    "        weight_REF /= m\n",
    "        REF_mean.append(weight_REF.T.dot(mu)[0])\n",
    "        REF_sd.append(np.sqrt(weight_REF.T.dot(sigma.dot(weight_REF))[0,0]))\n",
    "    return REF_sd, REF_mean, REF_weights \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32872547]\n",
      " [ 0.06617121]\n",
      " [ 0.01473561]\n",
      " [ 0.08192781]\n",
      " [ 0.04723716]\n",
      " [ 0.15060952]\n",
      " [ 0.09169677]\n",
      " [ 0.21889643]]\n",
      "[[  4.17489465e-01]\n",
      " [  1.46693607e-06]\n",
      " [  1.73936115e-07]\n",
      " [  5.80298886e-02]\n",
      " [  3.86855184e-06]\n",
      " [  1.57623427e-01]\n",
      " [  2.54469810e-02]\n",
      " [  3.41404730e-01]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~GY400/30.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly \n",
    "plotly.tools.set_credentials_file(username='GY400', api_key='IqLG54Iong7FLeX17uh6')\n",
    "\n",
    "true_ef_sd, true_ef_mean, true_opt_weight = MVEF(mean, cov)\n",
    "ref_sd, ref_mean, ref_weight = REF(mean, cov)\n",
    "\n",
    "#print(true_ef_sd)\n",
    "\n",
    "#print(ref_sd)\n",
    "#print(ref_mean)\n",
    "print(ref_weight[25])\n",
    "print(true_opt_weight[25])\n",
    "\n",
    "efficient_frontier = go.Scatter(\n",
    "                x = true_ef_sd,\n",
    "                y = true_ef_mean,\n",
    "                mode = 'markers'\n",
    "                )\n",
    "\n",
    "resampling_ef = go.Scatter(\n",
    "             x = ref_sd,\n",
    "             y = ref_mean,\n",
    "             mode = 'markers'\n",
    "             )\n",
    "\n",
    "py.iplot([efficient_frontier, resampling_ef])\n",
    "#py.iplot([resampling_ef])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge of REF: the Simulation Proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~GY400/34.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = len(mean)\n",
    "est_sample = np.random.multivariate_normal(mean, cov, size).T\n",
    "est_cov = np.cov(sample)\n",
    "est_mean = np.mean(sample, 1)\n",
    "\n",
    "assert(est_cov.shape == (size,size))\n",
    "\n",
    "mv_sd, mv_mean, mv_weights = MVEF(est_mean, est_cov)\n",
    "r_sd, r_mean, r_weights = REF(est_mean, est_cov, m=100)\n",
    "\n",
    "est_mv_ef_mean = []\n",
    "est_mv_ef_sd = []\n",
    "est_r_ef_mean = []\n",
    "est_r_ef_sd = []\n",
    "\n",
    "for weight_mv, weight_r in zip(mv_weights, r_weights):\n",
    "    est_mv_ef_mean.append(weight_mv.T.dot(mean)[0])\n",
    "    est_mv_ef_sd.append(np.sqrt(weight_mv.T.dot(cov.dot(weight_mv))[0,0]))\n",
    "    est_r_ef_mean.append(weight_r.T.dot(mean)[0])\n",
    "    est_r_ef_sd.append(np.sqrt(weight_r.T.dot(cov.dot(weight_r))[0,0]))\n",
    "\n",
    "est_mv_ef = go.Scatter(\n",
    "                x = est_mv_ef_sd,\n",
    "                y = est_mv_ef_mean,\n",
    "                name = 'mv',\n",
    "                mode = 'markers'\n",
    "                )\n",
    "\n",
    "est_resampling_ef = go.Scatter(\n",
    "             x = est_r_ef_sd,\n",
    "             y = est_r_ef_mean,\n",
    "             name = 'resampling',\n",
    "             mode = 'markers'\n",
    "             )\n",
    "\n",
    "py.iplot([est_mv_ef, est_resampling_ef])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
